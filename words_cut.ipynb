{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 获取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_1998_news_words():\n",
    "    words_path = './data/news_1_gram.json'\n",
    "    with open(words_path, 'r', encoding='utf-8') as f:\n",
    "        words = json.load(f)\n",
    "    return words\n",
    "\n",
    "def get_THUOCL_words():\n",
    "    data_path = './data/THUOCL'\n",
    "    # 得到文件列表中的所有文件名\n",
    "    files = os.listdir(data_path)\n",
    "    # 遍历文件名列表，将文件中的内容添加到words字典中\n",
    "    words = {}\n",
    "    for file in files:\n",
    "        with open(os.path.join(data_path, file), 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                line = line.split()\n",
    "                if len(line) == 2:\n",
    "                    words[line[0]] = line[1]\n",
    "        print(file, 'done')\n",
    "    return words\n",
    "\n",
    "\n",
    "\n",
    "def get_words_dic(data_name):\n",
    "    if data_name == '1998版新闻':\n",
    "       words = get_1998_news_words()\n",
    "    elif data_name == 'THUOCL清华数据源':\n",
    "       words = get_THUOCL_words()\n",
    "    elif data_name == '词库融合':\n",
    "       words = get_1998_news_words()\n",
    "       words.update(get_THUOCL_words())\n",
    "    return words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THUOCL_animal.txt done\n",
      "THUOCL_caijing.txt done\n",
      "THUOCL_car.txt done\n",
      "THUOCL_chengyu.txt done\n",
      "THUOCL_diming.txt done\n",
      "THUOCL_food.txt done\n",
      "THUOCL_IT.txt done\n",
      "THUOCL_law.txt done\n",
      "THUOCL_lishimingren.txt done\n",
      "THUOCL_medical.txt done\n",
      "THUOCL_poem.txt done\n",
      "信鸽: 220963\n",
      "黄蜂: 118861\n",
      "水母: 78147\n",
      "野猫: 62065\n",
      "宠物狗: 56875\n",
      "母狗: 56087\n",
      "毛毛虫: 48631\n",
      "猎豹: 48451\n",
      "犀牛: 46120\n",
      "萨摩: 84\n",
      "狼狗: 40979\n",
      "喜鹊: 40321\n",
      "梅花鹿: 37159\n",
      "牡蛎: 985\n",
      "毛驴: 32969\n",
      "母牛: 31741\n",
      "野牛: 27896\n",
      "多宝鱼: 23907\n",
      "小蜜蜂: 22680\n",
      "猿人: 21112\n",
      "猎狗: 20562\n",
      "小尾寒羊: 18980\n",
      "金枪鱼: 18892\n",
      "大黄蜂: 18504\n",
      "墨鱼: 17270\n",
      "扇贝: 16676\n",
      "毛滴虫: 16392\n",
      "鸰: 14603\n",
      "小雀: 13089\n",
      "苏眉: 12152\n",
      "狼犬: 11704\n",
      "黄粉虫: 11209\n",
      "野菊花: 375\n",
      "夜鹰: 10533\n",
      "导盲犬: 10113\n",
      "猫科动物: 9462\n",
      "利木赞牛: 9371\n",
      "目鱼: 9329\n",
      "文金: 9087\n",
      "越前龙: 8739\n",
      "野驴: 8582\n",
      "瓢虫: 8236\n",
      "九间: 7969\n",
      "软体动物: 7579\n",
      "鹡鸰: 7500\n",
      "蝇蛆: 6580\n",
      "家鸡: 6433\n",
      "河蚌: 6090\n",
      "全蝎: 97\n",
      "刺参: 5577\n",
      "灵长类动物: 5575\n",
      "鹮: 5069\n",
      "囊虫: 4996\n",
      "杜泊绵羊: 4587\n",
      "小鲤: 4440\n",
      "毛蟹: 4343\n",
      "鹩哥: 4205\n",
      "喷毒眼镜蛇: 4150\n",
      "文蛤: 3950\n",
      "斗牛犬: 3940\n",
      "野牦牛: 3938\n",
      "鸮: 3886\n",
      "寄居蟹: 3675\n",
      "鹦哥: 3500\n",
      "画眉鸟: 3483\n",
      "苏格兰牧羊犬: 3261\n",
      "台鸽: 3222\n",
      "狮子狗: 3184\n",
      "抹香鲸: 3138\n",
      "桃花水母: 3114\n",
      "小鸥: 2963\n",
      "小野猪: 2901\n",
      "五步蛇: 2888\n",
      "花寨: 2819\n",
      "疟原虫: 330\n",
      "濒危野生动物: 2726\n",
      "野生大熊猫: 2660\n",
      "青波: 2656\n",
      "克隆牛: 2647\n",
      "珠鸡: 2641\n",
      "猫鱼: 2595\n",
      "木回: 2595\n",
      "鱼胆: 2549\n",
      "种公猪: 2508\n",
      "灰鹤: 2354\n",
      "雄蜂: 2307\n",
      "杜宾犬: 2297\n",
      "纯种波尔山羊: 2223\n",
      "中白鹭: 2210\n",
      "卷尾: 2152\n",
      "阴道毛滴虫: 2134\n",
      "紫贝: 2005\n",
      "鮰鱼: 1976\n",
      "萨摩耶犬: 1970\n",
      "杜泊羊: 1859\n",
      "滩羊: 1794\n",
      "钱鼠: 1734\n",
      "浮游动物: 139\n",
      "轮虫: 1679\n",
      "元谋人: 1673\n"
     ]
    }
   ],
   "source": [
    "data_name = 'THUOCL清华数据源'\n",
    "words_dic = get_words_dic(data_name)\n",
    "# 展示字典的元素\n",
    "q = 100 \n",
    "for word, count in words_dic.items():\n",
    "    if q > 0:\n",
    "        print(f'{word}: {count}')\n",
    "        q -= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FMM(sentence, words_dic):\n",
    "    max_length = max(len(word) for word in words_dic)\n",
    "    sentence = sentence.strip()\n",
    "    words_length = len(sentence)\n",
    "    cut_word_list = []\n",
    "\n",
    "    while words_length > 0:\n",
    "        max_cut_length = min(max_length, words_length)\n",
    "        sub_sentence = sentence[0: max_cut_length]\n",
    "        while max_cut_length > 0: # 最长匹配\n",
    "            if sub_sentence in words_dic: # 在字典中\n",
    "                cut_word_list.append(sub_sentence)\n",
    "                break\n",
    "            elif max_cut_length == 1: # 不在字典中\n",
    "                cut_word_list.append(sub_sentence)\n",
    "                break\n",
    "            else: # 不在字典中，最大框长度-1\n",
    "                max_cut_length = max_cut_length - 1\n",
    "                sub_sentence = sub_sentence[0:max_cut_length]\n",
    "        sentence = sentence[max_cut_length:]\n",
    "        words_length = words_length - max_cut_length\n",
    "\n",
    "    return cut_word_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def BMM(sentence, words_dic):\n",
    "    max_length = max(len(word) for word in words_dic) # 统计词典中词的最长长度\n",
    "    sentence = sentence.strip()\n",
    "    words_length = len(sentence)\n",
    "    cut_word_list = []\n",
    "\n",
    "    while words_length > 0:\n",
    "        max_cut_length = min(max_length, words_length)\n",
    "        sub_sentence = sentence[-max_cut_length:] # 与FMM不同之处\n",
    "        while max_cut_length > 0:\n",
    "            if sub_sentence in words_dic:\n",
    "                cut_word_list.append(sub_sentence)\n",
    "                break\n",
    "            elif max_cut_length == 1:\n",
    "                cut_word_list.append(sub_sentence)\n",
    "                break\n",
    "            else:\n",
    "                max_cut_length = max_cut_length -1\n",
    "                sub_sentence = sub_sentence[-max_cut_length:]  # 与FMM不同之处\n",
    "        sentence = sentence[0:-max_cut_length] # 与FMM不同之处\n",
    "        words_length = words_length - max_cut_length\n",
    "    cut_word_list.reverse()\n",
    "\n",
    "    return cut_word_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bi-MM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实现双向匹配算法中的切词方法\n",
    "def Bi_MM(sentence, words_dic):\n",
    "    bmm_word_list = BMM(sentence, words_dic)\n",
    "    fmm_word_list = FMM(sentence, words_dic)\n",
    "    if bmm_word_list == fmm_word_list:\n",
    "        return bmm_word_list\n",
    "    else:\n",
    "        bmm_word_list_size = len(bmm_word_list)\n",
    "        fmm_word_list_size = len(fmm_word_list)\n",
    "        if bmm_word_list_size != fmm_word_list_size:\n",
    "            return bmm_word_list if bmm_word_list_size < fmm_word_list_size else fmm_word_list\n",
    "        else:\n",
    "            FMM_one_word_count = sum([1 for word in fmm_word_list if len(word) == 1])\n",
    "            BMM_one_word_count = sum([1 for word in bmm_word_list if len(word) == 1])\n",
    "            return fmm_word_list if BMM_one_word_count > FMM_one_word_count else bmm_word_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n-gram算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_dic = {\n",
    "    'FMM': FMM,\n",
    "    'BMM': BMM,\n",
    "    'Bi-MM': Bi_MM\n",
    "}\n",
    "\n",
    "data_name = [\n",
    "    '1998版新闻',\n",
    "    'THUOCL清华数据源',\n",
    "    '词库融合'\n",
    "]\n",
    "\n",
    "func = 'BMM'\n",
    "data_name = '1998版新闻'\n",
    "sentence = '为人民办公益事业' # 为人民办公益事业 我来到北京清华大学\n",
    "words_dic = get_words_dic(data_name)\n",
    "result = func_dic[func](sentence, words_dic)\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
